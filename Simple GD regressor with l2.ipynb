{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, alpha=0.0001, l_ratio=0.01, tol=0.001, max_iter=1000):\n",
    "   \n",
    "        self.alpha = alpha\n",
    "        self.l_ratio = l_ratio\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "             \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        w_current = np.random.uniform(-1, 1, size=n_features)\n",
    "        b_current = 0\n",
    "        cost = 10\n",
    "        \n",
    "        w_lst = []\n",
    "        grad_lst = []\n",
    "        costs = []\n",
    "        \n",
    "        for n_iter in range(self.max_iter):\n",
    "            y_current = X.dot(w_current) + b_current\n",
    "            \n",
    "            if np.abs(cost - mean_squared_error(y, y_current)) < self.tol:\n",
    "                break\n",
    "        \n",
    "            cost = np.mean((y - y_current)**2)\n",
    "            costs.append(cost)\n",
    "            \n",
    "            w_grad = -(2 / n_samples) * (y-y_current).dot(X) + 2 * self.alpha * w_current\n",
    "            b_grad = -(2 / n_samples) * np.sum(y - y_current) + 2 * self.alpha * b_current\n",
    "            \n",
    "            w_current -= self.l_ratio * w_grad\n",
    "            b_current -= self.l_ratio * b_grad\n",
    "            \n",
    "            w_lst.append(list(w_current))\n",
    "            grad_lst.append(np.sum(w_grad**2))\n",
    "\n",
    "        self.w = w_current\n",
    "        self.b = b_current\n",
    "        self.costs = costs\n",
    "        self.n_iter = n_iter\n",
    "        self.w_lst = np.array(w_lst)\n",
    "        self.grad = np.array(grad_lst)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "\n",
    "        y_pred = X.dot(self.w) + self.b\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:\n",
      "\n",
      "Ridge: 0.0\n",
      "\n",
      "my_reg: 0.0003\n",
      "\n",
      "SGD_Ridge with 10^(-4) * alpha: 0.0\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples = 10000)\n",
    "\n",
    "alpha=0.1\n",
    "\n",
    "print('MSE:')\n",
    "print()\n",
    "reg = Ridge(alpha=alpha)\n",
    "reg.fit(X, y)\n",
    "print('Ridge:', mean_squared_error(y, reg.predict(X)).round(4))\n",
    "print()\n",
    "my_reg = LinearRegression(l_ratio=0.01, tol=10**(-5), alpha=alpha*10**(-4), max_iter=1000)\n",
    "my_reg.fit(X, y)\n",
    "print('my_reg:', mean_squared_error(y, my_reg.predict(X)).round(4))\n",
    "print()\n",
    "sgd = SGDRegressor(alpha=alpha*10**(-4))\n",
    "sgd.fit(X, y)\n",
    "print('SGD_Ridge with 10^(-4) * alpha:', mean_squared_error(y, sgd.predict(X)).round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
